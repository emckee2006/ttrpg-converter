# M1.5: Database-Driven Architecture

**Author:** Gemini
**Date:** 2024-07-25
**Status:** Adopted

## 1. Executive Summary

This document outlines a foundational architectural shift for the TTRPG Converter. The original plan (M1) envisioned an in-memory processing model, which is insufficient for the project's long-term goals of handling large compendia, parallel processing, and complex asset management.

This new architecture, to be implemented before proceeding with the core engine tasks of M2, introduces a persistent, database-driven approach using **RavenDB Embedded**. This will provide a robust, scalable, and performant foundation for all future development.

## 2. Core Problem

The initial in-memory-per-run strategy presents several critical issues:

-   **Performance Bottleneck:** Re-processing all source compendia on every conversion run is not scalable.
-   **Concurrency Unsafe:** It provides no safe mechanism for parallel tasks to coordinate, leading to race conditions and data corruption.
-   **High Memory Usage:** Requires the entire dataset to be loaded into RAM.
-   **Complex State Management:** Requires developers to write and maintain complex, error-prone logic for caching and state management.

## 3. The RavenDB Embedded Solution

To address these issues, we will use **RavenDB Embedded** as the central data store for both the persistent compendium cache and the transient state of a conversion run.

### 3.1. Why RavenDB Embedded?

-   **Document-Oriented:** Perfectly suited for storing and indexing complex JSON-like documents (`CompendiumItem`, `AssetMapping`).
-   **ACID Transactions:** Guarantees data integrity and eliminates the risk of a corrupt cache.
-   **High-Performance, Indexed Lookups:** Allows for fast queries directly on disk, minimizing memory usage.
-   **Built-in Concurrency Control:** The session-based unit of work provides a robust, industry-standard solution for managing parallel reads and writes, eliminating the need for manual locking.

### 3.2. New CLI Command: `update-compendium`

A new, standalone command will be created to manage the persistent compendium cache.

-   **Responsibility:** Its sole purpose is to read from all source compendia (NeDB, LevelDB), resolve all conflicts, and populate a `CompendiumItems` collection in the central `compendium.db` RavenDB file.
-   **Execution:** This command will be run by the user once after setting up the project or whenever their FoundryVTT content changes.

### 3.3. The Conversion Workflow

1.  **Initialization:** The `ConversionStateManager` connects to the `compendium.db` file.
2.  **State Management:** For each conversion run, it creates **temporary collections** (e.g., `CustomItems_Run_XYZ`, `AssetMappings_Run_XYZ`) to isolate the run's state.
3.  **Parallel Processing:**
    -   All worker tasks perform fast, concurrent reads against the permanent `CompendiumItems` collection.
    -   When creating new entities or assets, tasks write to the temporary collections. RavenDB's transactional engine prevents race conditions.
4.  **Finalization:** The final output JSON files are generated by reading from the temporary collections.
5.  **Cleanup:** The temporary collections are dropped after the run is complete.

## 4. Impact on Future Milestones

This architecture provides the necessary foundation for all subsequent milestones:

-   **M2 (Core Engine):** The `CompendiumManager` and other core services will be built from the ground up to use the database, resulting in a simpler and more robust design.
-   **M3 (PF1e to PF2e):** The thousands of entity lookups required for this complex conversion will be fast and efficient.
-   **M4 (Enhancement Pipeline):** The goals of this milestone (performance, parallelism, asset handling) are directly addressed and fulfilled by this new architecture.

By implementing this foundational change now, we ensure that the project is built on a solid, scalable, and professional-grade architecture from the outset.
